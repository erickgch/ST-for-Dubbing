{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import math, statistics\n",
    "import csv\n",
    "import re\n",
    "\n",
    "path_on= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/on_eng/heroes*.csv\"\n",
    "path_off= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/off_eng/heroes*.csv\"\n",
    "path_mix= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/mixed_eng/heroes*.csv\"\n",
    "\n",
    "path_on_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/on_spa/heroes*.csv\"\n",
    "path_off_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/off_spa/heroes*.csv\"\n",
    "path_mix_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/mixed_spa/heroes*.csv\"\n",
    "\n",
    "# dat function returns all the frequency and intensity values for each word for each segment per path\n",
    "\n",
    "def dat_function(path):\n",
    "    freq_list = []\n",
    "    int_list = []\n",
    "\n",
    "    for fname in glob.glob(path):\n",
    "        df = pd.read_csv(fname, delimiter='|')\n",
    "        for index, row in df.iterrows():\n",
    "            if abs(row.f0_mean) > 0:\n",
    "                freq_list.append(row.f0_mean)\n",
    "            if abs(row.i0_mean) > 0:\n",
    "                int_list.append(row.i0_mean)\n",
    "            else:\n",
    "                pass\n",
    "    return freq_list, int_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_res = dat_function(path_on)\n",
    "off_res = dat_function(path_off)\n",
    "mix_res = dat_function(path_mix)\n",
    "on_sp_res = dat_function(path_on_sp)\n",
    "off_sp_res = dat_function(path_off_sp)\n",
    "mix_sp_res = dat_function(path_mix_sp)\n",
    "\n",
    "pairs = [(on_res, on_sp_res), (off_res, off_sp_res), (mix_res, mix_sp_res)]\n",
    "\n",
    "all_eng = (on_res[0] + off_res[0] + mix_res[0], on_res[1] + off_res[1] + mix_res[1])\n",
    "all_spa = (on_sp_res[0] + off_sp_res[0] + mix_sp_res[0], on_sp_res[1] + off_sp_res[1] + mix_sp_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQ\n",
      "\n",
      "english on  8.85821993820414 1.263712124324298\n",
      "english off  9.603564516478704 1.206925483779559\n",
      "english mixed  8.977168297816956 1.237321688667108\n",
      "\n",
      "INTENSITY\n",
      "\n",
      "spanish on  7.736198155872236 1.1587411549034985\n",
      "spanish off  9.290136948045738 1.1542584215810092\n",
      "spanish mixed  7.730712013092112 1.1277217029652018\n",
      "mean freq  -2.29208069603407\n",
      "mean int  -0.045192339592417904\n"
     ]
    }
   ],
   "source": [
    "print('FREQ\\n')\n",
    "print('english on ', statistics.stdev(on_res[0]), statistics.stdev(on_res[1]))\n",
    "print('english off ', statistics.stdev(off_res[0]), statistics.stdev(off_res[1]))\n",
    "print('english mixed ', statistics.stdev(mix_res[0]), statistics.stdev(mix_res[1]))\n",
    "print('\\nINTENSITY\\n')\n",
    "print('spanish on ', statistics.stdev(on_sp_res[0]), statistics.stdev(on_sp_res[1]))\n",
    "print('spanish off ', statistics.stdev(off_sp_res[0]), statistics.stdev(off_sp_res[1]))\n",
    "print('spanish mixed ', statistics.stdev(mix_sp_res[0]), statistics.stdev(mix_sp_res[1]))\n",
    "\n",
    "#absolute values\n",
    "freq_abs_mean = statistics.mean(all_eng[0])\n",
    "int_abs_mean = statistics.mean(all_eng[1])\n",
    "\n",
    "print('mean freq ',freq_abs_mean)\n",
    "print('mean int ',int_abs_mean)\n",
    "\n",
    "freq_abs_stdev = statistics.stdev(all_eng[0])\n",
    "int_abs_stdev = statistics.stdev(all_eng[1])\n",
    "\n",
    "#screen-dep values\n",
    "freq_on_mean = statistics.mean(on_res[0])\n",
    "freq_off_mean = statistics.mean(off_res[0])\n",
    "freq_mix_mean = statistics.mean(mix_res[0])\n",
    "\n",
    "freq_on_stdev = statistics.stdev(on_res[0])\n",
    "freq_off_stdev = statistics.stdev(off_res[0])\n",
    "freq_mix_stdev = statistics.stdev(mix_res[0])\n",
    "\n",
    "int_on_mean = statistics.mean(on_res[1])\n",
    "int_off_mean = statistics.mean(off_res[1])\n",
    "int_mix_mean = statistics.mean(mix_res[1])\n",
    "\n",
    "int_on_stdev = statistics.stdev(on_res[1])\n",
    "int_off_stdev = statistics.stdev(off_res[1])\n",
    "int_mix_stdev = statistics.stdev(mix_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import math, statistics\n",
    "import csv\n",
    "import re\n",
    "\n",
    "path_on= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/on_eng/heroes*.csv\"\n",
    "path_on_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/on_spa/heroes*.csv\"\n",
    "\n",
    "path_off= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/off_eng/heroes*.csv\"\n",
    "path_off_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/off_spa/heroes*.csv\"\n",
    "\n",
    "path_mix= r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/mixed_eng/heroes*.csv\"\n",
    "path_mix_sp = r\"C:/Users/erick/OneDrive/Desktop/MT-FBK-internship/on-off/mixed_spa/heroes*.csv\"\n",
    "\n",
    "# this func. gets the word, (shortened)id, f0_mean and i0_mean for each word for each segment file in the path\n",
    "def pre_peak_finder(path):\n",
    "    final_list = []\n",
    "    for fname in glob.glob(path):\n",
    "        temp_l = ()\n",
    "        temp_seg = []\n",
    "        t_df = pd.read_csv(fname, delimiter='|')\n",
    "        for index, row in t_df.iterrows():\n",
    "            id_i = str(row.id[:13])+str(row.id[24:])\n",
    "            temp_l = (row.word, id_i, row.f0_mean, row.i0_mean)\n",
    "            temp_seg.append(temp_l)\n",
    "            temp_l = ()\n",
    "        final_list.append(temp_seg)\n",
    "        temp_seg = []\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling pre_peak_finder func. Use these pairs as input for peak_finder func.\n",
    "\n",
    "a = pre_peak_finder(path_on)\n",
    "b = pre_peak_finder(path_on_sp)\n",
    "\n",
    "m = pre_peak_finder(path_off)\n",
    "n = pre_peak_finder(path_off_sp)\n",
    "\n",
    "x =  pre_peak_finder(path_mix)\n",
    "y =  pre_peak_finder(path_mix_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_peak_finder(f):\n",
    "    freq_peaks = []\n",
    "    int_peaks = []\n",
    "    ids_freq = []\n",
    "    ids_int = []\n",
    "    \n",
    "    for seg in f:\n",
    "        for w in seg:\n",
    "            # frequency peaks\n",
    "            if w[2] >= (freq_abs_mean + 2*freq_abs_stdev) or w[2] <= (freq_abs_mean - 2*freq_abs_stdev):\n",
    "                if seg not in freq_peaks:\n",
    "                    freq_peaks.append(seg)\n",
    "                else:\n",
    "                    pass\n",
    "                if w[1] not in ids_freq:\n",
    "                    ids_freq.append([w[1], w[0], w[2], w[3]])\n",
    "                else:\n",
    "                    pass\n",
    "            # intensity peaks\n",
    "            if w[3] >= (int_abs_mean + 2*int_abs_stdev) or w[3] <= (int_abs_mean - 2*int_abs_stdev):\n",
    "                int_peaks.append(seg)\n",
    "                if w[1] not in ids_int:\n",
    "                    ids_int.append([w[1], w[0], w[2], w[3]])\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return freq_peaks, int_peaks, ids_freq, ids_int\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     segment word_id         word  frequency  intensity\n",
       " 0    heroes_s2_10_.segment24       4     familiar    19.9629    -0.0484\n",
       " 1    heroes_s2_10_.segment38       1         solo    27.1037     0.0121\n",
       " 2    heroes_s2_10_.segment38       2          así    27.4934     0.0121\n",
       " 3    heroes_s2_10_.segment51       3     ocurrido    23.1611    -1.1494\n",
       " 4    heroes_s2_10_.segment67       1     mohinder   -23.9163    -0.6436\n",
       " ..                       ...     ...          ...        ...        ...\n",
       " 924  heroes_s3_9_ssegment313       6        hasta   -25.2302    -1.6368\n",
       " 925  heroes_s3_9_ssegment313       7          hoy   -23.2249     0.0674\n",
       " 926  heroes_s3_9_ssegment314       1         creo   -23.7746    -0.2052\n",
       " 927  heroes_s3_9_ssegment314       4           el   -36.9292    -2.5563\n",
       " 928  heroes_s3_9_ssegment314       5  catalizador   -26.8197    -1.0499\n",
       " \n",
       " [929 rows x 5 columns],\n",
       "                      segment word_id       word  frequency  intensity\n",
       " 0    heroes_s2_10_.segment32      11       suya     0.0000    -2.8799\n",
       " 1    heroes_s2_10_.segment54       8      brazo    -9.3345    -2.7788\n",
       " 2    heroes_s2_10_.segment55       3      quién     7.8309    -2.7788\n",
       " 3    heroes_s2_10_.segment56       5        que    -4.6340    -2.6558\n",
       " 4    heroes_s2_10_.segment58       7       solo     0.0000    -2.7788\n",
       " ..                       ...     ...        ...        ...        ...\n",
       " 820  heroes_s3_9_ssegment312       4  diferente    -4.2958    -2.5563\n",
       " 821  heroes_s3_9_ssegment312       5          a     0.0000    -3.1975\n",
       " 822  heroes_s3_9_ssegment312       8      demás   -24.9292    -2.5563\n",
       " 823  heroes_s3_9_ssegment313       3         lo     0.0000    -2.8739\n",
       " 824  heroes_s3_9_ssegment314       4         el   -36.9292    -2.5563\n",
       " \n",
       " [825 rows x 5 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs_en_on = segment_peak_finder(a)\n",
    "segs_spa_on = segment_peak_finder(b)\n",
    "\n",
    "segs_en_off = segment_peak_finder(m)\n",
    "segs_spa_off = segment_peak_finder(n)\n",
    "\n",
    "segs_en_mix = segment_peak_finder(x)\n",
    "segs_spa_mix = segment_peak_finder(y)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def df_maker(data):\n",
    "    my_df_freq = pd.DataFrame({'segment': [i[0].split('.word')[0] for i in data[2]], \n",
    "                          'word_id': [i[0].split('.word')[1] for i in data[2]], \n",
    "                          'word': [i[1] for i in data[2]], 'frequency': [i[2] for i in data[2]],\n",
    "                         'intensity': [i[3] for i in data[2]]})\n",
    "    \n",
    "    my_df_int = pd.DataFrame({'segment': [i[0].split('.word')[0] for i in data[3]], \n",
    "                          'word_id': [i[0].split('.word')[1] for i in data[3]], \n",
    "                          'word': [i[1] for i in data[3]], 'frequency': [i[2] for i in data[3]],\n",
    "                         'intensity': [i[3] for i in data[3]]})\n",
    "    \n",
    "    return my_df_freq, my_df_int\n",
    "\n",
    "df_maker(segs_spa_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on/freq  97\n",
      "on/int  66\n",
      "off/freq  46\n",
      "off/int  19\n",
      "mix/freq  63\n",
      "mix/int  56\n"
     ]
    }
   ],
   "source": [
    "# obtaining common elements between paired datasets\n",
    "\n",
    "def commonalities(a, b):\n",
    "        \n",
    "    common_freq_ = set.intersection(set(a[0].segment), set(b[0].segment))\n",
    "    common_int_ = set.intersection(set(a[1].segment), set(b[1].segment))\n",
    "    \n",
    "    return common_freq_, common_int_\n",
    "\n",
    "print('on/freq ',len(commonalities(df_maker(segs_en_on), df_maker(segs_spa_on))[0]))\n",
    "print('on/int ',len(commonalities(df_maker(segs_en_on), df_maker(segs_spa_on))[1]))\n",
    "\n",
    "print('off/freq ',len(commonalities(df_maker(segs_en_off), df_maker(segs_spa_off))[0]))\n",
    "print('off/int ',len(commonalities(df_maker(segs_en_off), df_maker(segs_spa_off))[1]))\n",
    "\n",
    "print('mix/freq ',len(commonalities(df_maker(segs_en_mix), df_maker(segs_spa_mix))[0]))\n",
    "print('mix/int ',len(commonalities(df_maker(segs_en_mix), df_maker(segs_spa_mix))[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of some English files didn't match those of their Spanish counterparts. The issue was fixed by editing the csv files manually. The files in the code below contain the corrected names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maker(segs_spa_on)[1].to_csv('segments_int_spanish_on_test.csv')\n",
    "df_maker(segs_spa_off)[1].to_csv('segments_int_spanish_off_test.csv')\n",
    "df_maker(segs_spa_mix)[1].to_csv('segments_int_spanish_mix_test.csv')\n",
    "df_maker(segs_en_on)[1].to_csv('segments_int_english_on_test.csv')\n",
    "df_maker(segs_en_off)[1].to_csv('segments_int_english_off_test.csv')\n",
    "df_maker(segs_en_mix)[1].to_csv('segments_int_english_mix_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp_on_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_spanish_on_test.csv')\n",
    "df_sp_off_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_spanish_off_test.csv')\n",
    "df_sp_mix_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_spanish_mix_test.csv')\n",
    "df_en_on_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_english_on_test.csv')\n",
    "df_en_off_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_english_off_test.csv')\n",
    "df_en_mix_f = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_english_mix_test.csv')\n",
    "\n",
    "df_sp_on_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_spanish_on_test.csv')\n",
    "df_sp_off_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_spanish_off_test.csv')\n",
    "df_sp_mix_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_spanish_mix_test.csv')\n",
    "df_en_on_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_english_on_test.csv')\n",
    "df_en_off_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_english_off_test.csv')\n",
    "df_en_mix_i = pd.read_csv('C:/Users/erick/OneDrive/Desktop/pros_results/new_peaks/segments_int_english_mix_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables containing the set of segments with concurrent peaks\n",
    "\n",
    "common_on_freq = set.intersection(set(df_en_on_f.segment), set(df_sp_on_f.segment))\n",
    "common_off_freq = set.intersection(set(df_en_off_f.segment), set(df_sp_off_f.segment))\n",
    "common_mix_freq = set.intersection(set(df_en_mix_f.segment), set(df_sp_mix_f.segment))\n",
    "\n",
    "common_on_int = set.intersection(set(df_en_on_i.segment), set(df_sp_on_i.segment))\n",
    "common_off_int = set.intersection(set(df_en_off_i.segment), set(df_sp_off_i.segment))\n",
    "common_mix_int = set.intersection(set(df_en_mix_i.segment), set(df_sp_mix_i.segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('freq on: ', len(common_on_freq))\n",
    "print('freq off: ', len(common_off_freq))\n",
    "print('freq mix: ', len(common_mix_freq))\n",
    "\n",
    "print('int on: ', len(common_on_int))\n",
    "print('int off: ', len(common_off_int))\n",
    "print('int mix: ', len(common_mix_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
